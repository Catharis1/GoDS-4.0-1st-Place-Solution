{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10758863,"sourceType":"datasetVersion","datasetId":6673561},{"sourceId":10760064,"sourceType":"datasetVersion","datasetId":6674436},{"sourceId":10761088,"sourceType":"datasetVersion","datasetId":6675097}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold\nimport torch\nimport torch.nn as nn\nfrom torch.utils.checkpoint import checkpoint\nfrom torch.utils.data import Dataset,DataLoader\nfrom tokenizers import AddedToken\n\nfrom sklearn import metrics\nfrom torch.nn import functional as F\nfrom tqdm import tqdm\nfrom transformers import (\n    AdamW,\n    AutoConfig,\n    AutoModel,\n    AutoTokenizer,\n    get_cosine_schedule_with_warmup,\n    get_linear_schedule_with_warmup,\n    DataCollatorWithPadding\n)\nimport warnings\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\n\nfrom torch.optim import lr_scheduler\nfrom torch.nn import Parameter\nimport time\n\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-03T19:09:19.329396Z","iopub.execute_input":"2025-03-03T19:09:19.329697Z","iopub.status.idle":"2025-03-03T19:09:38.881761Z","shell.execute_reply.started":"2025-03-03T19:09:19.329674Z","shell.execute_reply":"2025-03-03T19:09:38.880739Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/gods-4-0-dataset/train (8).csv\")\ntest = pd.read_csv(\"/kaggle/input/gods-4-0-dataset/test (6).csv\")\nss = pd.read_csv(\"/kaggle/input/gods-4-0-dataset/SampleSubmission (13).csv\")\n\ntrain.dropna(inplace=True)\ntest.dropna(inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T19:09:38.882890Z","iopub.execute_input":"2025-03-03T19:09:38.883506Z","iopub.status.idle":"2025-03-03T19:09:41.860046Z","shell.execute_reply.started":"2025-03-03T19:09:38.883480Z","shell.execute_reply":"2025-03-03T19:09:41.859269Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"T2ID = {\n    \"relationship-and-family-issues\": 0,\n    \"anxiety\": 1,\n    \"depression\": 2,\n    \"ptsd-and-trauma\": 3,\n    \"suicidal-thoughts-and-self-harm\": 4\n}\n\nID2T = {v: k for k, v in T2ID.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T19:09:41.861658Z","iopub.execute_input":"2025-03-03T19:09:41.862013Z","iopub.status.idle":"2025-03-03T19:09:41.866079Z","shell.execute_reply.started":"2025-03-03T19:09:41.861980Z","shell.execute_reply":"2025-03-03T19:09:41.865199Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train[\"target_id\"] = train[\"target\"].map(T2ID)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T19:09:41.867567Z","iopub.execute_input":"2025-03-03T19:09:41.867893Z","iopub.status.idle":"2025-03-03T19:09:41.910983Z","shell.execute_reply.started":"2025-03-03T19:09:41.867871Z","shell.execute_reply":"2025-03-03T19:09:41.910015Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"cfg = {\"model_name\": \"microsoft/deberta-v3-base\",\n    \"max_len\": 512,\n    \"freeze\" : False,\n\n    \"fold_num\": 5,\n    \"val_fold\": 0,\n    \"learning_rate\": 1e-05,\n    \"min_lr\": 8e-6,\n    \"T_max\": 600,\n    \"valid_batch_size\": 16,\n    'train_batch_size' : 8,\n \n    \"epochs\": 2, \n    \"accumulation_steps\": 6,\n    \"val_steps\": 375,\n    \n    \"scheduler\" : 'cosine',\n    \" warmup_epochs\": 1,\n\n    \"gradient_checkpoint\" : False,\n    'tokenizer' : AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\"),\n    \n    \"input\": \"input/\",\n    \"output\": \"output/\"\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T19:09:41.911982Z","iopub.execute_input":"2025-03-03T19:09:41.912262Z","iopub.status.idle":"2025-03-03T19:09:44.191169Z","shell.execute_reply.started":"2025-03-03T19:09:41.912232Z","shell.execute_reply":"2025-03-03T19:09:44.190179Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad0c6154e66b427f869dd1081492a90c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04021847221a44089671e57ccd56db32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4832e3861cc3455fb90e787e2ce1a933"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"cfg['n_accumulate'] = 4#\ncfg['dropout'] = 0.2\ncfg['apex'] = True\ncfg[\"grad_norm\"] = 20\ncfg[\"gradient_checkpoint\"] = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T19:09:44.192557Z","iopub.execute_input":"2025-03-03T19:09:44.192883Z","iopub.status.idle":"2025-03-03T19:09:44.196721Z","shell.execute_reply.started":"2025-03-03T19:09:44.192848Z","shell.execute_reply":"2025-03-03T19:09:44.196004Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Add Special Tokens (\\n & \\n\\n)","metadata":{}},{"cell_type":"code","source":"cfg[\"tokenizer\"].add_tokens([AddedToken(\"\\n\", normalized=False)])\ncfg[\"tokenizer\"].add_tokens([AddedToken(\"\\n\\n\", normalized=False)])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T19:09:44.197604Z","iopub.execute_input":"2025-03-03T19:09:44.197876Z","iopub.status.idle":"2025-03-03T19:09:44.230691Z","shell.execute_reply.started":"2025-03-03T19:09:44.197846Z","shell.execute_reply":"2025-03-03T19:09:44.230023Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## Helper Functions","metadata":{}},{"cell_type":"code","source":"def set_seed(seed=42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T19:09:44.232292Z","iopub.execute_input":"2025-03-03T19:09:44.232489Z","iopub.status.idle":"2025-03-03T19:09:44.249022Z","shell.execute_reply.started":"2025-03-03T19:09:44.232471Z","shell.execute_reply":"2025-03-03T19:09:44.248363Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n        \ndef prepare_input(cfg, text, tokenizer):\n\n    inputs = tokenizer.encode_plus(\n        text,\n        return_tensors=None,\n        add_special_tokens=True,\n        max_length=cfg[\"max_len\"],\n        padding='max_length',\n        truncation=True\n    )\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long) \n    return inputs\n\n\ndef collate(inputs):\n\n    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n    for k, v in inputs.items():\n        inputs[k] = inputs[k][:,:mask_len]\n    return inputs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def optimizer_scheduler(model,steps):\n        param_optimizer = list(model.named_parameters())\n        no_decay = [\"bias\", \"LayerNorm.weight\"]\n        optimizer_parameters = [\n            {\n                \"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay) and p.requires_grad],\n                \"weight_decay\": 0.003,\n            },\n            {\n                \"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay) and p.requires_grad],\n                \"weight_decay\": 0.0,\n            },\n        ]\n        opt = AdamW(optimizer_parameters, lr=cfg['learning_rate'])\n\n        sch = get_cosine_schedule_with_warmup(\n            opt,\n            num_warmup_steps=0,\n            num_training_steps=steps,#self.num_train_steps,\n            last_epoch=-1,\n        )\n        return opt, sch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T22:46:15.453941Z","iopub.execute_input":"2025-02-15T22:46:15.454128Z","iopub.status.idle":"2025-02-15T22:46:15.460979Z","shell.execute_reply.started":"2025-02-15T22:46:15.454111Z","shell.execute_reply":"2025-02-15T22:46:15.460336Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"class Dataset(Dataset):\n    def __init__(self, df, test_phase=False):\n        self.test_phase = test_phase\n        self.cfg = cfg\n        if not self.test_phase:\n            self.labels = df['target_id'].values\n        self.tokenizer = cfg['tokenizer']\n        self.sep_token = self.tokenizer.sep_token\n        self.texts = df[\"title\"].values + self.sep_token + df['content'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        output = {}\n        output[\"inputs\"] = prepare_input(self.cfg, self.texts[item], self.tokenizer)\n        if not self.test_phase:\n            output[\"labels\"] = torch.tensor(self.labels[item], dtype=torch.float) \n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T03:04:24.866943Z","iopub.execute_input":"2025-02-16T03:04:24.867414Z","iopub.status.idle":"2025-02-16T03:04:24.873746Z","shell.execute_reply.started":"2025-02-16T03:04:24.867371Z","shell.execute_reply":"2025-02-16T03:04:24.872954Z"}},"outputs":[],"execution_count":67},{"cell_type":"markdown","source":"## Pooling & Model","metadata":{}},{"cell_type":"code","source":"def get_last_hidden_state(backbone_outputs):\n    last_hidden_state = backbone_outputs[0]\n    return last_hidden_state\n\n\ndef get_all_hidden_states(backbone_outputs):\n    all_hidden_states = torch.stack(backbone_outputs[1])\n    return all_hidden_states\n\n\ndef get_input_ids(inputs):\n    return inputs['input_ids']\n\n\ndef get_attention_mask(inputs):\n    return inputs['attention_mask']\n\n\nclass MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling, self).__init__()\n\n    def forward(self, inputs, backbone_outputs):\n        attention_mask = get_attention_mask(inputs)\n        last_hidden_state = get_last_hidden_state(backbone_outputs)\n\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings\n    \nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.drop = nn.Dropout(p=cfg[\"dropout\"])\n        \n        self.config = AutoConfig.from_pretrained(cfg[\"model_name\"])\n        #self.config.hidden_dropout = 0.\n        self.config.hidden_dropout_prob = 0.007\n        #self.config.attention_dropout = 0.\n        self.config.attention_probs_dropout_prob = 0.008\n\n        self.model = AutoModel.from_pretrained(cfg[\"model_name\"], config=self.config)\n        self.model.resize_token_embeddings(len(cfg[\"tokenizer\"]))\n\n        #odd_layer_freeze(self.model)\n        if cfg[\"gradient_checkpoint\"]:\n            print('Enabling Grad Checkpointing')\n            self.model.gradient_checkpointing_enable()  \n        if cfg[\"freeze\"]:\n            print('freezing params')\n            for parameter in self.model.parameters():\n                parameter.requires_grad = False\n        self.pool = MeanPooling()\n        self.fc = nn.Sequential(\n            nn.Linear(self.config.hidden_size, 5),\n        )\n        \n    def forward(self, inputs):        \n        out = self.model(**inputs)\n        out = self.pool(inputs, out)\n        out = self.drop(out)\n        out = self.fc(out)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T22:46:15.477296Z","iopub.execute_input":"2025-02-15T22:46:15.477582Z","iopub.status.idle":"2025-02-15T22:46:15.490363Z","shell.execute_reply.started":"2025-02-15T22:46:15.477553Z","shell.execute_reply":"2025-02-15T22:46:15.489713Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, dataloader, device):\n    model.train()\n\n    total = 0\n    running_loss = 0.0\n    losses = AverageMeter()\n    scaler = torch.cuda.amp.GradScaler(enabled=cfg[\"apex\"])\n    lr = []\n    bar = tqdm(dataloader, total=len(dataloader))\n    steps = len(dataloader)\n    \n    all_preds = np.array([])\n    all_groud_truth = np.array([])\n    \n    for step, data in enumerate(bar):\n        \n        inputs = data.pop(\"inputs\")\n        labels = data.pop(\"labels\")\n        labels = labels.long()\n        inputs = collate(inputs)\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        \n        with torch.cuda.amp.autocast(enabled=cfg[\"apex\"]):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n        loss = loss / cfg['n_accumulate']\n        \n        losses.update(loss.item(), batch_size)\n        scaler.scale(loss).backward()\n        \n        if (step + 1) % cfg['n_accumulate'] == 0 or step == steps:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n            if scheduler:\n                scheduler.step()\n\n\n        epoch_loss = losses.avg\n        #acc = correct / total\n\n        bar.set_postfix(\n            Loss=epoch_loss, LR=optimizer.param_groups[0]['lr'])\n        \n        lr.append(optimizer.param_groups[0]['lr'])\n\n    return losses.avg\n\n@torch.no_grad()\ndef evaluate(model, dataloader, device):\n    model.eval()\n\n    total = 0\n    losses = AverageMeter()\n    correct = 0\n    preds = []\n    y_test = []\n    for data in dataloader:\n        inputs = data.pop(\"inputs\")\n        labels = data.pop(\"labels\")\n        labels = labels.long()\n        inputs = collate(inputs)\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n\n        outputs = model(inputs)\n\n        loss = criterion(outputs, labels)\n\n        losses.update(loss.item(), batch_size)\n\n        preds.append(outputs.softmax(dim=1).argmax(dim=1).detach().cpu().numpy())\n        y_test.append(labels.detach().cpu().numpy())\n        \n    \n    epoch_loss = losses\n    preds = np.concatenate(preds)\n    y_test = np.concatenate(y_test)\n\n    return losses.avg, preds, y_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T22:46:15.521854Z","iopub.execute_input":"2025-02-15T22:46:15.522139Z","iopub.status.idle":"2025-02-15T22:46:15.540199Z","shell.execute_reply.started":"2025-02-15T22:46:15.522111Z","shell.execute_reply":"2025-02-15T22:46:15.539501Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def start_training(model, optimizer, scheduler, device, num_epochs,train_loader,valid_loader,fold=0):\n    start = time.time()\n    best_score = 0\n    history = {\"Train Loss\": [], \"Valid Loss\": [],\"LR\": []}\n    \n\n    for epoch in range(1, num_epochs + 1):\n        print(\"Epoch: \", epoch)\n        train_epoch_loss = train_one_epoch(\n            model, optimizer, scheduler, dataloader=train_loader, device=cfg[\"device\"]\n        )\n\n        val_epoch_loss, preds, y_test = evaluate(\n            model, valid_loader, device=cfg[\"device\"]\n        )\n        score = accuracy_score(preds, y_test)\n\n        print(f\"Acc Score: {score}\")\n        print(f\"Train Loss: {train_epoch_loss}\")\n        print(f\"Valid Loss: {val_epoch_loss}\")\n\n\n        history[\"Train Loss\"].append(train_epoch_loss)\n        history[\"Valid Loss\"].append(val_epoch_loss)\n\n\n        if score >= best_score:\n            print(\n                f\"Score Improved ({best_score} ---> {score})\"\n            )\n            best_score = score\n            PATH = f\"fold_{fold}.bin\"\n            torch.save(model.state_dict(), PATH)\n            \n            print(f\"Model Saved\")\n            best_y = preds\n\n        print()\n\n    end = time.time()\n    time_elapsed = end - start\n    print(\n        \"Training complete in {:.0f}h {:.0f}m {:.0f}s\".format(\n            time_elapsed // 3600,\n            (time_elapsed % 3600) // 60,\n            (time_elapsed % 3600) % 60,\n        )\n    )\n    print(\n        \"Best Score: {:.4f}\".format(\n            best_score\n        )\n    )\n\n\n    return history, best_y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T22:46:15.540925Z","iopub.execute_input":"2025-02-15T22:46:15.541135Z","iopub.status.idle":"2025-02-15T22:46:15.558157Z","shell.execute_reply.started":"2025-02-15T22:46:15.541116Z","shell.execute_reply":"2025-02-15T22:46:15.557376Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## Validation Strategy: Stratified K Folds","metadata":{}},{"cell_type":"code","source":"def make_folds(train_df, n_splits):\n\n    train_df[\"fold\"] = -1\n    X = train_df[\"content\"]\n    y = train_df[\"target\"]\n    skf = StratifiedKFold(n_splits=5)\n\n    for i, (train_index, val_index) in enumerate(skf.split(X, y)):\n        train_df.loc[val_index, \"fold\"] = i\n    return train_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T22:46:15.558924Z","iopub.execute_input":"2025-02-15T22:46:15.559232Z","iopub.status.idle":"2025-02-15T22:46:15.575056Z","shell.execute_reply.started":"2025-02-15T22:46:15.559178Z","shell.execute_reply":"2025-02-15T22:46:15.574256Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"train = make_folds(train, 5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T22:46:15.643086Z","iopub.execute_input":"2025-02-15T22:46:15.643405Z","iopub.status.idle":"2025-02-15T22:46:15.671810Z","shell.execute_reply.started":"2025-02-15T22:46:15.643380Z","shell.execute_reply":"2025-02-15T22:46:15.671003Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"train.reset_index(inplace=True, drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T22:46:15.672715Z","iopub.execute_input":"2025-02-15T22:46:15.673241Z","iopub.status.idle":"2025-02-15T22:46:15.676639Z","shell.execute_reply.started":"2025-02-15T22:46:15.673213Z","shell.execute_reply":"2025-02-15T22:46:15.675839Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\ndef run_folds() :\n    \n    for fold in range(1, 5) :\n\n        print(f'--------------------------------Training Fold {fold+1}/5---------------------------------')\n        train_ = train[train.fold!=fold]\n        valid_ = train[train.fold==fold]\n        \n        print(f'train shape : {len(train_)}')\n        print(f'valid shape : {len(valid_)}')\n        \n        train_dataset = Dataset(\n                                    train_\n                            )\n        valid_dataset = Dataset(\n                                    valid_\n        )\n        train_loader = DataLoader(\n                train_dataset,\n                batch_size=cfg[\"train_batch_size\"],\n                num_workers=4,\n                shuffle=True,\n                pin_memory=True,\n                drop_last=True\n                    )\n        valid_loader = DataLoader(\n            valid_dataset,\n            batch_size=cfg[\"valid_batch_size\"],\n            num_workers=4,\n            shuffle=False,\n            pin_memory=True,\n        )\n        \n        model = Model()\n        model.to(cfg['device'])\n        \n        steps = len(train_loader)\n        \n        optimizer,_ = optimizer_scheduler(model,steps)\n        scheduler = lr_scheduler.CosineAnnealingLR(\n                        optimizer, T_max=cfg['T_max'], eta_min=cfg['min_lr'])\n        \n        \n        history = start_training(\n                        model, optimizer, scheduler, cfg['device'], cfg['epochs'] ,train_loader=train_loader,valid_loader=valid_loader,fold=fold)\n        torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T22:46:15.693152Z","iopub.execute_input":"2025-02-15T22:46:15.693403Z","iopub.status.idle":"2025-02-15T22:46:15.704930Z","shell.execute_reply.started":"2025-02-15T22:46:15.693384Z","shell.execute_reply":"2025-02-15T22:46:15.704260Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"cfg[\"device\"] = \"cuda\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T22:46:15.705858Z","iopub.execute_input":"2025-02-15T22:46:15.706105Z","iopub.status.idle":"2025-02-15T22:46:15.720891Z","shell.execute_reply.started":"2025-02-15T22:46:15.706075Z","shell.execute_reply":"2025-02-15T22:46:15.720166Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"run_folds()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T22:46:15.721611Z","iopub.execute_input":"2025-02-15T22:46:15.721861Z","iopub.status.idle":"2025-02-16T02:02:36.357959Z","shell.execute_reply.started":"2025-02-15T22:46:15.721842Z","shell.execute_reply":"2025-02-16T02:02:36.356855Z"}},"outputs":[{"name":"stdout","text":"--------------------------------Training Fold 2/5---------------------------------\ntrain shape : 17527\nvalid shape : 4382\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5573f69215e94d1aa015bd0ac882c002"}},"metadata":{}},{"name":"stdout","text":"Epoch:  1\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2190/2190 [22:35<00:00,  1.62it/s, LR=8.04e-6, Loss=0.199]\n","output_type":"stream"},{"name":"stdout","text":"Acc Score: 0.783888635326335\nTrain Loss: 0.19922036789867975\nValid Loss: 0.6022728112450151\nScore Improved (0 ---> 0.783888635326335)\nModel Saved\n\nEpoch:  2\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2190/2190 [22:34<00:00,  1.62it/s, LR=9.85e-6, Loss=0.14] \n","output_type":"stream"},{"name":"stdout","text":"Acc Score: 0.7832040164308535\nTrain Loss: 0.14010992081470142\nValid Loss: 0.5957958937126553\n\nTraining complete in 0h 49m 5s\nBest Score: 0.7839\n--------------------------------Training Fold 3/5---------------------------------\ntrain shape : 17527\nvalid shape : 4382\nEpoch:  1\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2190/2190 [22:29<00:00,  1.62it/s, LR=8.04e-6, Loss=0.205]\n","output_type":"stream"},{"name":"stdout","text":"Acc Score: 0.7809219534459151\nTrain Loss: 0.2047937544513511\nValid Loss: 0.6170639854378485\nScore Improved (0 ---> 0.7809219534459151)\nModel Saved\n\nEpoch:  2\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2190/2190 [22:27<00:00,  1.63it/s, LR=9.85e-6, Loss=0.144]\n","output_type":"stream"},{"name":"stdout","text":"Acc Score: 0.792332268370607\nTrain Loss: 0.14358798552593685\nValid Loss: 0.5817745146768815\nScore Improved (0.7809219534459151 ---> 0.792332268370607)\nModel Saved\n\nTraining complete in 0h 48m 54s\nBest Score: 0.7923\n--------------------------------Training Fold 4/5---------------------------------\ntrain shape : 17527\nvalid shape : 4382\nEpoch:  1\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2190/2190 [22:34<00:00,  1.62it/s, LR=8.04e-6, Loss=0.208]\n","output_type":"stream"},{"name":"stdout","text":"Acc Score: 0.7850296668188042\nTrain Loss: 0.20797410196365287\nValid Loss: 0.5994100058693583\nScore Improved (0 ---> 0.7850296668188042)\nModel Saved\n\nEpoch:  2\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2190/2190 [22:32<00:00,  1.62it/s, LR=9.85e-6, Loss=0.144]\n","output_type":"stream"},{"name":"stdout","text":"Acc Score: 0.7948425376540392\nTrain Loss: 0.14353907135523616\nValid Loss: 0.5814797155174802\nScore Improved (0.7850296668188042 ---> 0.7948425376540392)\nModel Saved\n\nTraining complete in 0h 49m 4s\nBest Score: 0.7948\n--------------------------------Training Fold 5/5---------------------------------\ntrain shape : 17528\nvalid shape : 4381\nEpoch:  1\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2191/2191 [22:32<00:00,  1.62it/s, LR=8.04e-6, Loss=0.201]\n","output_type":"stream"},{"name":"stdout","text":"Acc Score: 0.7772198128281215\nTrain Loss: 0.2009999109342837\nValid Loss: 0.6455964157364189\nScore Improved (0 ---> 0.7772198128281215)\nModel Saved\n\nEpoch:  2\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2191/2191 [22:36<00:00,  1.61it/s, LR=9.85e-6, Loss=0.14] \n","output_type":"stream"},{"name":"stdout","text":"Acc Score: 0.7858936315909609\nTrain Loss: 0.14014928839294838\nValid Loss: 0.5997025298217855\nScore Improved (0.7772198128281215 ---> 0.7858936315909609)\nModel Saved\n\nTraining complete in 0h 49m 6s\nBest Score: 0.7859\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/gods-4-0-dataset/test (6).csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T02:57:45.196984Z","iopub.execute_input":"2025-02-16T02:57:45.197354Z","iopub.status.idle":"2025-02-16T02:57:45.337017Z","shell.execute_reply.started":"2025-02-16T02:57:45.197324Z","shell.execute_reply":"2025-02-16T02:57:45.336094Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"test[\"content\"] = test[\"content\"].fillna(\" \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T02:58:36.686479Z","iopub.execute_input":"2025-02-16T02:58:36.686775Z","iopub.status.idle":"2025-02-16T02:58:36.692507Z","shell.execute_reply.started":"2025-02-16T02:58:36.686752Z","shell.execute_reply":"2025-02-16T02:58:36.691619Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"valid_dataset = Dataset(df = test, test_phase=True)\ntest_loader = DataLoader(\n                valid_dataset,\n                batch_size=cfg[\"valid_batch_size\"],\n                num_workers=4,\n                shuffle=False,\n                pin_memory=True,\n            )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T03:06:02.480702Z","iopub.execute_input":"2025-02-16T03:06:02.480988Z","iopub.status.idle":"2025-02-16T03:06:02.497737Z","shell.execute_reply.started":"2025-02-16T03:06:02.480967Z","shell.execute_reply":"2025-02-16T03:06:02.497011Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"final_preds = []\nfor fold in range(5):\n    model = Model()\n    model.to(cfg['device'])\n    path = \"/kaggle/input/deberta-base-fold0/fold_0.bin\" if fold ==0 else f\"fold_{fold}.bin\"\n\n    model.load_state_dict(\n        torch.load(path)\n    )\n    preds = infer(model, test_loader, 'cuda')\n    final_preds.append(preds)\n\nfinal_preds = np.mean(final_preds, 0) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T03:06:02.766872Z","iopub.execute_input":"2025-02-16T03:06:02.767151Z","iopub.status.idle":"2025-02-16T03:11:45.779216Z","shell.execute_reply.started":"2025-02-16T03:06:02.767128Z","shell.execute_reply":"2025-02-16T03:11:45.778156Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 154/154 [01:05<00:00,  2.34it/s]\n100%|██████████| 154/154 [01:06<00:00,  2.33it/s]\n100%|██████████| 154/154 [01:05<00:00,  2.33it/s]\n100%|██████████| 154/154 [01:05<00:00,  2.33it/s]\n100%|██████████| 154/154 [01:05<00:00,  2.33it/s]\n","output_type":"stream"}],"execution_count":76},{"cell_type":"code","source":"for i in range(5):\n    test[f'deb_base_preds_class_{i}'] = final_preds[:, i]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T03:13:22.590984Z","iopub.execute_input":"2025-02-16T03:13:22.591317Z","iopub.status.idle":"2025-02-16T03:13:22.598131Z","shell.execute_reply.started":"2025-02-16T03:13:22.591288Z","shell.execute_reply":"2025-02-16T03:13:22.597265Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"test = test[[col for col in test.columns if col not in [\"title\", \"content\"]]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T03:14:52.081903Z","iopub.execute_input":"2025-02-16T03:14:52.082280Z","iopub.status.idle":"2025-02-16T03:14:52.087733Z","shell.execute_reply.started":"2025-02-16T03:14:52.082247Z","shell.execute_reply":"2025-02-16T03:14:52.087023Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"test.to_csv(\"deb_base_test.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T03:14:52.480948Z","iopub.execute_input":"2025-02-16T03:14:52.481268Z","iopub.status.idle":"2025-02-16T03:14:52.501075Z","shell.execute_reply.started":"2025-02-16T03:14:52.481239Z","shell.execute_reply":"2025-02-16T03:14:52.500263Z"}},"outputs":[],"execution_count":85}]}